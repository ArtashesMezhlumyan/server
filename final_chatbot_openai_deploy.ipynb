{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "h9roJQqeRq6G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9roJQqeRq6G",
    "outputId": "193ad625-971e-4194-8f25-86a96461b10b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba47604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ba47604",
    "outputId": "d4547103-512e-4ee8-e337-a9ff83388f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.0/276.0 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.3/264.3 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.4/422.4 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain  pypdf  openai python-dotenv tiktoken docarray chromadb fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c7e121",
   "metadata": {
    "id": "e0c7e121"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace 'your_actual_api_key' with your real OpenAI API key\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "# 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 MY\n",
    "# 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 VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83558969-e5aa-4fbc-933c-9c1534decf0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83558969-e5aa-4fbc-933c-9c1534decf0a",
    "outputId": "07802b90-5938-45e5-98b6-1fe566fec2a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4BVao3L8y1b4",
   "metadata": {
    "id": "4BVao3L8y1b4"
   },
   "source": [
    "# Create a chatbot that works on your MULTIPLE documents\n",
    "\n",
    "> Indented block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "qdsog_06-RDK",
   "metadata": {
    "id": "qdsog_06-RDK"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain, ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import openai\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "OZNp4ZFP-RBd",
   "metadata": {
    "id": "OZNp4ZFP-RBd"
   },
   "outputs": [],
   "source": [
    "def load_db(file, chain_type, k):\n",
    "    # load documents\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    # split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    # define embedding\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0),\n",
    "        chain_type=chain_type,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True\n",
    "    )\n",
    "    # custom_template = \"\"\"You are Customer Support Chatbot who works at Ingo Armenia, an automated service which answers to user questions. \\\n",
    "    #                 You first greet the customer, then answer to questions. IMPORTANT: Do not answer to any question which is not connected to health insurance.\n",
    "    # Chat History:\n",
    "    # {chat_history}\n",
    "    # Follow Up Input: {question}\n",
    "    # Standalone question:\"\"\"\n",
    "\n",
    "    # CUSTOM_QUESTION_PROMPT = PromptTemplate.from_template(custom_template)\n",
    "\n",
    "    # memory = ConversationBufferMemory(memory_key='chat_history', output_key='answer',input_key=\"question\", return_messages=True)\n",
    "    # qa = ConversationalRetrievalChain.from_llm(\n",
    "    #     llm=ChatOpenAI(model_name=llm_name, temperature=0),\n",
    "    #     chain_type=chain_type,\n",
    "    #     retriever=retriever,\n",
    "    #     #return_source_documents=True,\n",
    "    #     #return_generated_question=True,\n",
    "    #     condense_question_prompt=CUSTOM_QUESTION_PROMPT,\n",
    "    #     memory=memory\n",
    "    # )\n",
    "\n",
    "    return qa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "x2p5Zm1m-Q_0",
   "metadata": {
    "id": "x2p5Zm1m-Q_0"
   },
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "\n",
    "    # context = \"\"\" role:system - Context: You are Customer Support Chatbot who works at Ingo Armenia, an automated service which answers to user questions. \\\n",
    "    #                 You first greet the customer, then answer to questions. IMPORTANT: Do not answer to any question which is not connected to health insurance.\\\n",
    "    #                 Chat history: \"\"\"\n",
    "\n",
    "    #context = [{\"role\": \"system\", \"content\": \"You are a Customer Support Chatbot who works at Ingo Armenia, an automated service that answers user questions. You first greet the customer, then answer questions. IMPORTANT: Do not answer any question not related to health insurance.\"}]\n",
    "\n",
    "    def __init__(self,loaded_file, **params):\n",
    "        super(cbfs, self).__init__(**params)\n",
    "        self.panels = []\n",
    "        self.loaded_file = loaded_file\n",
    "        self.qa = load_db(self.loaded_file,\"stuff\", 4)\n",
    "\n",
    "    def call_load_db(self, count):\n",
    "        if count == 0 or file_input.value is None:  # init or no file specified:\n",
    "            return f\"Loaded File: {self.loaded_file}\"\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")  # local copy\n",
    "            self.loaded_file = file_input.filename\n",
    "            button_load.button_style=\"outline\"\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "            button_load.button_style=\"solid\"\n",
    "        self.clr_history()\n",
    "        return f\"Loaded File: {self.loaded_file}\"\n",
    "\n",
    "\n",
    "    # def convchain(self, query):\n",
    "    #     if not query:\n",
    "    #         return [\"User:\", \"\"]\n",
    "\n",
    "\n",
    "    #     self.context.append({\"role\": \"user\", \"content\": query})\n",
    "    #     result = self.qa({\"question\": str(self.context), \"chat_history\": self.chat_history})\n",
    "    #     self.context.append({\"role\": \"assistant\", \"content\": result['answer']})\n",
    "    #     self.chat_history.extend([(\"User Question: \" + query, \"Chatbot Answer: \" + result[\"answer\"])])\n",
    "    #     #self.chat_history.append((query, str(self.chat_history)))\n",
    "    #     self.db_query = result[\"generated_question\"]\n",
    "    #     self.db_response = result[\"source_documents\"]\n",
    "    #     self.answer = result['answer']\n",
    "    #     self.panels.extend([\n",
    "    #         [\"User:\", query],\n",
    "    #         [\"ChatBot:\", self.answer]\n",
    "    #     ])\n",
    "    #     #inp.value = ''  # clears loading indicator when cleared\n",
    "\n",
    "    #     return result\n",
    "\n",
    "\n",
    "    # def convchain(self, query):\n",
    "    #     if not query:\n",
    "    #         return [\"User:\", \"\"]\n",
    "\n",
    "    #     self.context = self.context +  f\" role:assistant - question: {query}\"\n",
    "    #     result = self.qa({\"question\": self.context, \"chat_history\": self.chat_history})\n",
    "    #     self.context = self.context + f\" role:user - answer: {result['answer']}\"\n",
    "    #     self.chat_history.extend([(\"User Question: \" + query, \"Chatbot Answer: \" + result[\"answer\"])])\n",
    "    #     #self.chat_history.append((query, str(self.chat_history)))\n",
    "    #     self.db_query = result[\"generated_question\"]\n",
    "    #     self.db_response = result[\"source_documents\"]\n",
    "    #     self.answer = result['answer']\n",
    "    #     self.panels.extend([\n",
    "    #         [\"User:\", query],\n",
    "    #         [\"ChatBot:\", self.answer]\n",
    "    #     ])\n",
    "    #     #inp.value = ''  # clears loading indicator when cleared\n",
    "\n",
    "    #     return result\n",
    "\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return [\"User:\", \"\"]\n",
    "        context = \" Context: You are Customer Support Chatbot who works at Ingo Armenia, an automated service which answers to user questions. \\\n",
    "                    IMPORTANT: Do not answer to any question which is not connected to health insurance. If you don't know the answer to the question tell the user to call to the customer. \\\n",
    "                     \"\n",
    "        result = self.qa({\"question\": context + query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.extend([(\"User Question: \" + query, \"Chatbot Answer: \" + result[\"answer\"])])\n",
    "        #self.chat_history.append((query, str(self.chat_history)))\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result['answer']\n",
    "        self.panels.extend([\n",
    "            [\"User:\", query],\n",
    "            [\"ChatBot:\", self.answer]\n",
    "        ])\n",
    "\n",
    "\n",
    "        #inp.value = ''  # clears loading indicator when cleared\n",
    "\n",
    "        return result['answer']\n",
    "\n",
    "    @param.depends('db_query ', )\n",
    "    def get_lquest(self):\n",
    "        if not self.db_query:\n",
    "            return [\"Last question to DB:\", \"no DB accesses so far\"]\n",
    "        return [\"DB query:\", self.db_query]\n",
    "\n",
    "    @param.depends('db_response', )\n",
    "    def get_sources(self):\n",
    "        if not self.db_response:\n",
    "            return\n",
    "        rlist = [\"Result of DB lookup:\"]\n",
    "        for doc in self.db_response:\n",
    "            rlist.append(doc)\n",
    "        return rlist\n",
    "\n",
    "    @param.depends('convchain', 'clr_history')\n",
    "    def get_chats(self):\n",
    "        if not self.chat_history:\n",
    "            return [\"No History Yet\"]\n",
    "        rlist = [\"Current Chat History variable\"]\n",
    "        for exchange in self.chat_history:\n",
    "            rlist.append(exchange)\n",
    "        return rlist\n",
    "\n",
    "    def clr_history(self, count=0):\n",
    "        self.chat_history = []\n",
    "        return\n",
    "\n",
    "\n",
    "        return history_entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "sgLUKrMS-Q99",
   "metadata": {
    "id": "sgLUKrMS-Q99"
   },
   "outputs": [],
   "source": [
    "# Instantiate the cbfs class\n",
    "chatbot_mult = cbfs('/content/drive/MyDrive/data/IBM_health/IBM_health_eng.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9NiWMTVd-Q5P",
   "metadata": {
    "id": "9NiWMTVd-Q5P"
   },
   "outputs": [],
   "source": [
    "companies_dict = {'IBM':'/content/drive/MyDrive/data/IBM_health/IBM_health_eng.pdf','Apple':'/content/drive/MyDrive/data/apple_health/apple_health_eng.pdf',\n",
    "                   'Cognize':'/content/drive/MyDrive/data/cognize_health/cognize_health_eng.pdf','Tesla':'/content/drive/MyDrive/data/tesla_health/tesla_health_eng.pdf',\n",
    "                   'Tumo':'/content/drive/MyDrive/data/tumo_health/tumo_health_eng.pdf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2laLpPlP-Q3H",
   "metadata": {
    "id": "2laLpPlP-Q3H"
   },
   "outputs": [],
   "source": [
    "# loaded_file_path = \"/content/drive/MyDrive/data/tumo_health/tumo_health_eng.pdf\"\n",
    "# my_cbfs_instance = cbfs(loaded_file=loaded_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "Bemv_HFdyxVD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bemv_HFdyxVD",
    "outputId": "1a676078-0ea9-4ee5-e2da-27e257c96c57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# company name finder\n",
    "# from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "\n",
    "# # List of companies\n",
    "df = pd.read_csv('/content/drive/MyDrive/data/list_of_companies/list_of_companies.csv')\n",
    "companies = df['List'].tolist()\n",
    "\n",
    "# # Find the closest match using fuzzywuzzy's process.extractOne\n",
    "# best_match, similarity_score = process.extractOne(user_input, companies)\n",
    "\n",
    "# Set a threshold similarity score for considering a match\n",
    " # You can adjust this based on your needs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1-xPuZp49vc0",
   "metadata": {
    "id": "1-xPuZp49vc0"
   },
   "source": [
    "TeleBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "rCX843CPyxTA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCX843CPyxTA",
    "outputId": "32ea7d2c-9c48-43e3-c2e0-f547c09c15f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyTelegramBotAPI\n",
      "  Downloading pyTelegramBotAPI-4.13.0.tar.gz (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.8/232.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting deep_translator\n",
      "  Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pyTelegramBotAPI) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (4.11.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2023.7.22)\n",
      "Building wheels for collected packages: pyTelegramBotAPI\n",
      "  Building wheel for pyTelegramBotAPI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyTelegramBotAPI: filename=pyTelegramBotAPI-4.13.0-py3-none-any.whl size=214529 sha256=b7f2c45b5da731dff53fd2ab0ffd69456a7f3100b217c6d9399be4f1f3defb62\n",
      "  Stored in directory: /root/.cache/pip/wheels/f7/1a/3b/41e1ce64625e3f11567085dc79043d9fa573a2cc39f9938556\n",
      "Successfully built pyTelegramBotAPI\n",
      "Installing collected packages: pyTelegramBotAPI, deep_translator\n",
      "Successfully installed deep_translator-1.11.4 pyTelegramBotAPI-4.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyTelegramBotAPI deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "wAdVPEk0yxRP",
   "metadata": {
    "id": "wAdVPEk0yxRP"
   },
   "outputs": [],
   "source": [
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "translator_am = GoogleTranslator(source='en', target='hy')\n",
    "translator_en = GoogleTranslator(source='hy', target='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "nIK9hwwdyxLt",
   "metadata": {
    "id": "nIK9hwwdyxLt"
   },
   "outputs": [],
   "source": [
    "import telebot\n",
    "from telebot import types\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "\n",
    "TOKEN = '6312556829:AAFdYgkH63hz9sFV3hJXYDW-RZKDPVhYrOM'\n",
    "bot = telebot.TeleBot(TOKEN)\n",
    "\n",
    "dat = []\n",
    "\n",
    "@bot.message_handler(commands=['start'])\n",
    "def handle_start(message):\n",
    "    dat.clear()\n",
    "    bot.send_message(message.chat.id, \"Բարեւ Ձեզ! Ես Հաճախորդների Աջակցման Չաթբոտ եմ, աշխատում եմ ԻՆԳՈ ԱՐՄԵՆԻԱ ապահովագրական ՓԲԸ-ում: Խնդրում ենք լատինատառ և անգլերեն լեզվով մուտքագրել ձեր աշխատավայրի անվանումը:\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_text_message(message):\n",
    "\n",
    "    best_match, similarity_score = process.extractOne(str(message.text), companies)\n",
    "    threshold = 70\n",
    "    if dat:\n",
    "      input_text = translator_en.translate(message.text)\n",
    "      chatbot_mult = cbfs(loaded_file=companies_dict[str(dat[0])])\n",
    "      response = chatbot_mult.convchain(input_text)\n",
    "      bot.send_message(message.chat.id, translator_am.translate(response))\n",
    "\n",
    "    elif similarity_score >= threshold:\n",
    "        dat.append(str(best_match))\n",
    "        bot.send_message(message.chat.id, f'Դուք աշխատում եք {best_match} ընկերությունում և ունեք առողջության ապահովագրության ծրագիր տրամադրված ԻՆԳՈ ԱՐՄԵՆԻԱ ապահովագրական ՓԲԸ-ի կողմից: Ես պատրաստ եմ պատասխանել ձեր ցանկացաց հարցի կապված առողջապահական ծառայությունների հետ:')\n",
    "        chatbot_mult = cbfs(loaded_file=companies_dict[str(best_match)])\n",
    "\n",
    "    else:\n",
    "        bot.send_message(message.chat.id, 'Դուք սխալ եք նշել ձեր ընկերության անվանումը կամ չունեք մեր ընկերությունում առողջության ապահովագրություն:')\n",
    "\n",
    "\n",
    "\n",
    "# @bot.message_handler(func=lambda message: True)\n",
    "# def answer_questions(message):\n",
    "\n",
    "#       input_text = translator_en.translate(message.text)\n",
    "#       chatbot_mult = cbfs(loaded_file=companies_dict[str(company)])\n",
    "#       response = chatbot_mult.convchain(input_text)\n",
    "#       bot.send_message(translator_am.translate(response))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "HK8eXqkeyxJ5",
   "metadata": {
    "id": "HK8eXqkeyxJ5"
   },
   "outputs": [],
   "source": [
    "bot.polling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8qs3k3eVnTU3",
   "metadata": {
    "id": "8qs3k3eVnTU3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7OZSwg0nnTTC",
   "metadata": {
    "id": "7OZSwg0nnTTC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ltp2sVUOnTRN",
   "metadata": {
    "id": "Ltp2sVUOnTRN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JHGzs0x8nTPk",
   "metadata": {
    "id": "JHGzs0x8nTPk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TxSLKa7wnTN2",
   "metadata": {
    "id": "TxSLKa7wnTN2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blrxezr_nTMB",
   "metadata": {
    "id": "blrxezr_nTMB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WsCrmSQ6nTKQ",
   "metadata": {
    "id": "WsCrmSQ6nTKQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wJ8KeghonTIf",
   "metadata": {
    "id": "wJ8KeghonTIf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7S1NVn9rnTGt",
   "metadata": {
    "id": "7S1NVn9rnTGt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VdrCQ8xqnTE-",
   "metadata": {
    "id": "VdrCQ8xqnTE-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edi8lPFonTAC",
   "metadata": {
    "id": "edi8lPFonTAC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "31e0742e-2085-4635-b87d-6596925f1077"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
